{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": "# 03 - Model Training: Computer Price Prediction\n\nThis notebook trains and evaluates models to predict computer prices.\n\n**Data is pre-processed in notebook 02 with:**\n- Features with >60% missing values removed\n- CPU/GPU matching with close neighbor and family mean imputation\n- Complete benchmark features: mark, rank, value, price for both CPU and GPU\n- Target leakage columns excluded (cpu_match_score, gpu_match_score, Ofertas)\n\n**Models compared:**\n1. Baseline (DummyRegressor - predicts mean)\n2. Ridge Regression (L2 regularization)\n3. RandomForestRegressor\n4. HistGradientBoostingRegressor\n5. CatBoostRegressor (with native categorical handling)\n6. CatBoost Quantile models (for price range prediction)\n\n**Metrics:**\n- RMSE (primary)\n- MAE\n- R²\n- MAPE\n\n---"
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## 1. Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": "import pandas as pd\nimport numpy as np\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport sys\nimport warnings\n\n# Add src to path\nsys.path.append('..')\n\n# Reload modules\nfor mod in ['src.modeling', 'modeling', 'src.features', 'features']:\n    if mod in sys.modules:\n        del sys.modules[mod]\n\nfrom src.modeling import (\n    infer_feature_types,\n    get_feature_summary,\n    build_sklearn_pipeline,\n    build_catboost_model,\n    prepare_catboost_data,\n    evaluate_sklearn_cv,\n    evaluate_predictions,\n    compare_models,\n    save_model,\n    load_features_data,\n    CATBOOST_AVAILABLE\n)\n\nfrom src.features import get_feature_columns\n\nfrom sklearn.model_selection import train_test_split\n\n# Display settings\npd.set_option('display.max_columns', 50)\npd.set_option('display.float_format', '{:.2f}'.format)\nsns.set_theme(style='whitegrid')\nwarnings.filterwarnings('ignore')\n\nprint(\"Libraries loaded!\")\nprint(f\"CatBoost available: {CATBOOST_AVAILABLE}\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": "<cell_type>markdown</cell_type>## 2. Load Pre-Processed Data\n\nData has been prepared in notebook 02:\n- Rows without target removed\n- Features with >60% missing values removed\n- Only engineered features (starting with _) included"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path('../data')\n",
    "\n",
    "# Try to load parquet, fall back to CSV\n",
    "try:\n",
    "    df = pd.read_parquet(DATA_DIR / 'db_features.parquet')\n",
    "    print(\"Loaded from parquet\")\n",
    "except (ImportError, FileNotFoundError):\n",
    "    df = pd.read_csv(DATA_DIR / 'db_features.csv')\n",
    "    print(\"Loaded from CSV\")\n",
    "\n",
    "print(f\"\\nDataset shape: {df.shape}\")\n",
    "print(f\"Rows: {len(df):,}\")\n",
    "print(f\"Columns: {len(df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check target variable\n",
    "TARGET_COL = '_precio_num'\n",
    "\n",
    "print(f\"Target: {TARGET_COL}\")\n",
    "print(f\"  Non-null: {df[TARGET_COL].notna().sum():,}\")\n",
    "print(f\"  Min: {df[TARGET_COL].min():,.2f}\")\n",
    "print(f\"  Max: {df[TARGET_COL].max():,.2f}\")\n",
    "print(f\"  Mean: {df[TARGET_COL].mean():,.2f}\")\n",
    "print(f\"  Median: {df[TARGET_COL].median():,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": "<cell_type>markdown</cell_type>## 3. Prepare Features\n\nUse pre-computed feature types from the features module."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": "# Get feature types (data is already prepared in notebook 02)\nfeature_cols, numeric_cols, categorical_cols = get_feature_columns(df, TARGET_COL)\n\nprint(f\"Total features: {len(feature_cols)}\")\nprint(f\"  Numeric: {len(numeric_cols)}\")\nprint(f\"  Categorical: {len(categorical_cols)}\")\n\nprint(f\"\\nNumeric features: {numeric_cols}\")\nprint(f\"Categorical features: {categorical_cols}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show feature summary\n",
    "summary = get_feature_summary(df, numeric_cols, categorical_cols)\n",
    "\n",
    "print(\"=== Numeric Features ===\")\n",
    "display(summary[summary['type'] == 'numeric'].head(20))\n",
    "\n",
    "print(\"\\n=== Categorical Features (sample) ===\")\n",
    "display(summary[summary['type'] == 'categorical'].head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": "# Prepare X and y (data is already cleaned, no need to filter)\nX = df[feature_cols].copy()\ny = df[TARGET_COL].copy()\n\nprint(f\"Training data shape: X={X.shape}, y={y.shape}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split for final evaluation\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train: {len(X_train):,} samples\")\n",
    "print(f\"Test: {len(X_test):,} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## 4. Train and Evaluate Models\n",
    "\n",
    "We'll train multiple models and compare their performance using cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store results\n",
    "all_results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "### 4.1 Baseline Model (DummyRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"BASELINE MODEL (Predict Mean)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "baseline_pipeline = build_sklearn_pipeline('dummy', numeric_cols, categorical_cols)\n",
    "baseline_results = evaluate_sklearn_cv(baseline_pipeline, X_train, y_train, cv=5)\n",
    "\n",
    "all_results['Baseline (Mean)'] = baseline_results\n",
    "\n",
    "print(f\"\\nCross-Validation Results:\")\n",
    "print(f\"  RMSE: {baseline_results['rmse_mean']:,.2f} (+/- {baseline_results['rmse_std']:,.2f})\")\n",
    "print(f\"  MAE:  {baseline_results['mae_mean']:,.2f} (+/- {baseline_results['mae_std']:,.2f})\")\n",
    "print(f\"  R²:   {baseline_results['r2_mean']:.4f} (+/- {baseline_results['r2_std']:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4pd7pumatry",
   "source": "### 4.2 Ridge Regression",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "9t15b537d8v",
   "source": "print(\"=\" * 60)\nprint(\"RIDGE REGRESSION\")\nprint(\"=\" * 60)\n\nridge_pipeline = build_sklearn_pipeline('ridge', numeric_cols, categorical_cols)\nridge_results = evaluate_sklearn_cv(ridge_pipeline, X_train, y_train, cv=5)\n\nall_results['Ridge'] = ridge_results\n\nprint(f\"\\nCross-Validation Results:\")\nprint(f\"  RMSE: {ridge_results['rmse_mean']:,.2f} (+/- {ridge_results['rmse_std']:,.2f})\")\nprint(f\"  MAE:  {ridge_results['mae_mean']:,.2f} (+/- {ridge_results['mae_std']:,.2f})\")\nprint(f\"  R²:   {ridge_results['r2_mean']:.4f} (+/- {ridge_results['r2_std']:.4f})\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": "### 4.3 Random Forest"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"RANDOM FOREST\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "rf_pipeline = build_sklearn_pipeline('random_forest', numeric_cols, categorical_cols)\n",
    "rf_results = evaluate_sklearn_cv(rf_pipeline, X_train, y_train, cv=5)\n",
    "\n",
    "all_results['Random Forest'] = rf_results\n",
    "\n",
    "print(f\"\\nCross-Validation Results:\")\n",
    "print(f\"  RMSE: {rf_results['rmse_mean']:,.2f} (+/- {rf_results['rmse_std']:,.2f})\")\n",
    "print(f\"  MAE:  {rf_results['mae_mean']:,.2f} (+/- {rf_results['mae_std']:,.2f})\")\n",
    "print(f\"  R²:   {rf_results['r2_mean']:.4f} (+/- {rf_results['r2_std']:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": "### 4.4 HistGradientBoosting"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"HIST GRADIENT BOOSTING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "hgb_pipeline = build_sklearn_pipeline('hist_gradient_boosting', numeric_cols, categorical_cols)\n",
    "hgb_results = evaluate_sklearn_cv(hgb_pipeline, X_train, y_train, cv=5)\n",
    "\n",
    "all_results['HistGradientBoosting'] = hgb_results\n",
    "\n",
    "print(f\"\\nCross-Validation Results:\")\n",
    "print(f\"  RMSE: {hgb_results['rmse_mean']:,.2f} (+/- {hgb_results['rmse_std']:,.2f})\")\n",
    "print(f\"  MAE:  {hgb_results['mae_mean']:,.2f} (+/- {hgb_results['mae_std']:,.2f})\")\n",
    "print(f\"  R²:   {hgb_results['r2_mean']:.4f} (+/- {hgb_results['r2_std']:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": "### 4.5 CatBoost (if available)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": "if CATBOOST_AVAILABLE:\n    from sklearn.model_selection import cross_val_score\n    from catboost import CatBoostRegressor\n    \n    print(\"=\" * 60)\n    print(\"CATBOOST\")\n    print(\"=\" * 60)\n    \n    # Prepare data for CatBoost (data is already cleaned from notebook 02)\n    X_cb, y_cb = prepare_catboost_data(\n        df.copy(),\n        numeric_cols,\n        categorical_cols,\n        TARGET_COL\n    )\n    \n    X_cb_train, X_cb_test, y_cb_train, y_cb_test = train_test_split(\n        X_cb, y_cb, test_size=0.2, random_state=42\n    )\n    \n    # Build CatBoost model\n    cat_model = build_catboost_model(categorical_cols, loss_function='RMSE')\n    \n    # Cross-validation using sklearn\n    neg_rmse_scores = cross_val_score(\n        cat_model, X_cb_train, y_cb_train, \n        cv=5, scoring='neg_root_mean_squared_error'\n    )\n    neg_mae_scores = cross_val_score(\n        cat_model, X_cb_train, y_cb_train,\n        cv=5, scoring='neg_mean_absolute_error'\n    )\n    r2_scores = cross_val_score(\n        cat_model, X_cb_train, y_cb_train,\n        cv=5, scoring='r2'\n    )\n    \n    cat_results = {\n        'rmse_mean': -neg_rmse_scores.mean(),\n        'rmse_std': neg_rmse_scores.std(),\n        'mae_mean': -neg_mae_scores.mean(),\n        'mae_std': neg_mae_scores.std(),\n        'r2_mean': r2_scores.mean(),\n        'r2_std': r2_scores.std(),\n    }\n    \n    all_results['CatBoost'] = cat_results\n    \n    print(f\"\\nCross-Validation Results:\")\n    print(f\"  RMSE: {cat_results['rmse_mean']:,.2f} (+/- {cat_results['rmse_std']:,.2f})\")\n    print(f\"  MAE:  {cat_results['mae_mean']:,.2f} (+/- {cat_results['mae_std']:,.2f})\")\n    print(f\"  R²:   {cat_results['r2_mean']:.4f} (+/- {cat_results['r2_std']:.4f})\")\nelse:\n    print(\"CatBoost not available. Install with: pip install catboost\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "## 5. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all models\n",
    "comparison = compare_models(all_results)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"MODEL COMPARISON (sorted by RMSE)\")\n",
    "print(\"=\" * 80)\n",
    "display(comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comparison\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# RMSE\n",
    "ax = axes[0]\n",
    "ax.barh(comparison['Model'], comparison['rmse_mean'], xerr=comparison['rmse_std'], capsize=5)\n",
    "ax.set_xlabel('RMSE (€)')\n",
    "ax.set_title('RMSE by Model')\n",
    "ax.invert_yaxis()\n",
    "\n",
    "# MAE\n",
    "ax = axes[1]\n",
    "ax.barh(comparison['Model'], comparison['mae_mean'], xerr=comparison['mae_std'], capsize=5, color='orange')\n",
    "ax.set_xlabel('MAE (€)')\n",
    "ax.set_title('MAE by Model')\n",
    "ax.invert_yaxis()\n",
    "\n",
    "# R²\n",
    "ax = axes[2]\n",
    "ax.barh(comparison['Model'], comparison['r2_mean'], xerr=comparison['r2_std'], capsize=5, color='green')\n",
    "ax.set_xlabel('R²')\n",
    "ax.set_title('R² by Model')\n",
    "ax.invert_yaxis()\n",
    "ax.set_xlim(0, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-24",
   "metadata": {},
   "source": [
    "## 6. Train Best Model on Full Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": "# Select best model based on RMSE\nbest_model_name = comparison.iloc[0]['Model']\nprint(f\"Best model: {best_model_name}\")\n\n# Train on full training data\nif best_model_name == 'CatBoost' and CATBOOST_AVAILABLE:\n    # Train CatBoost\n    final_model = build_catboost_model(categorical_cols, loss_function='RMSE')\n    final_model.fit(X_cb_train, y_cb_train)\n    \n    # Evaluate on test set\n    y_pred = final_model.predict(X_cb_test)\n    final_metrics = evaluate_predictions(y_cb_test, y_pred)\n    \n    # Feature columns for metadata\n    model_feature_cols = list(X_cb.columns)\n    \nelse:\n    # Train sklearn model\n    model_type_map = {\n        'Random Forest': 'random_forest',\n        'HistGradientBoosting': 'hist_gradient_boosting',\n        'Ridge': 'ridge',\n        'ElasticNet': 'elasticnet',\n        'Baseline (Mean)': 'dummy'\n    }\n    model_type = model_type_map.get(best_model_name, 'random_forest')\n    \n    final_model = build_sklearn_pipeline(model_type, numeric_cols, categorical_cols)\n    final_model.fit(X_train, y_train)\n    \n    # Evaluate on test set\n    y_pred = final_model.predict(X_test)\n    final_metrics = evaluate_predictions(y_test, y_pred)\n    \n    model_feature_cols = feature_cols\n\nprint(f\"\\nTest Set Performance:\")\nprint(f\"  RMSE: {final_metrics['rmse']:,.2f}\")\nprint(f\"  MAE:  {final_metrics['mae']:,.2f}\")\nprint(f\"  R²:   {final_metrics['r2']:.4f}\")\nprint(f\"  MAPE: {final_metrics['mape']:.2f}%\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-26",
   "metadata": {},
   "source": [
    "## 7. Prediction Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual vs Predicted plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Get the right y values\n",
    "if best_model_name == 'CatBoost' and CATBOOST_AVAILABLE:\n",
    "    y_actual = y_cb_test\n",
    "else:\n",
    "    y_actual = y_test\n",
    "\n",
    "# Scatter plot\n",
    "ax = axes[0]\n",
    "ax.scatter(y_actual, y_pred, alpha=0.3, s=10)\n",
    "ax.plot([0, y_actual.max()], [0, y_actual.max()], 'r--', lw=2, label='Perfect prediction')\n",
    "ax.set_xlabel('Actual Price (€)')\n",
    "ax.set_ylabel('Predicted Price (€)')\n",
    "ax.set_title('Actual vs Predicted Prices')\n",
    "ax.legend()\n",
    "\n",
    "# Residuals\n",
    "ax = axes[1]\n",
    "residuals = y_actual - y_pred\n",
    "ax.hist(residuals, bins=50, edgecolor='black', alpha=0.7)\n",
    "ax.axvline(0, color='red', linestyle='--', lw=2)\n",
    "ax.set_xlabel('Residual (€)')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title(f'Residual Distribution (Mean: {residuals.mean():,.0f}€, Std: {residuals.std():,.0f}€)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error by price range\n",
    "results_df = pd.DataFrame({\n",
    "    'actual': y_actual,\n",
    "    'predicted': y_pred,\n",
    "    'error': np.abs(y_actual - y_pred),\n",
    "    'pct_error': np.abs(y_actual - y_pred) / y_actual * 100\n",
    "})\n",
    "\n",
    "# Price bins\n",
    "results_df['price_bin'] = pd.cut(results_df['actual'], \n",
    "                                  bins=[0, 500, 1000, 1500, 2000, 3000, 10000],\n",
    "                                  labels=['0-500', '500-1000', '1000-1500', '1500-2000', '2000-3000', '3000+'])\n",
    "\n",
    "# Stats by price range\n",
    "print(\"=== Error by Price Range ===\")\n",
    "error_by_range = results_df.groupby('price_bin', observed=True).agg({\n",
    "    'actual': 'count',\n",
    "    'error': ['mean', 'std'],\n",
    "    'pct_error': 'mean'\n",
    "}).round(2)\n",
    "error_by_range.columns = ['Count', 'MAE (€)', 'Std (€)', 'MAPE (%)']\n",
    "display(error_by_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-29",
   "metadata": {},
   "source": [
    "## 8. CatBoost Quantile Regression (Price Range Prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-30",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CATBOOST_AVAILABLE:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"QUANTILE REGRESSION (Price Range Prediction)\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Train models for different quantiles\n",
    "    quantiles = [0.1, 0.5, 0.9]\n",
    "    quantile_models = {}\n",
    "    \n",
    "    for q in quantiles:\n",
    "        print(f\"\\nTraining quantile={q} model...\")\n",
    "        q_model = build_catboost_model(categorical_cols, loss_function='Quantile', quantile=q)\n",
    "        q_model.fit(X_cb_train, y_cb_train)\n",
    "        quantile_models[q] = q_model\n",
    "    \n",
    "    # Predict on test set\n",
    "    pred_low = quantile_models[0.1].predict(X_cb_test)\n",
    "    pred_mid = quantile_models[0.5].predict(X_cb_test)\n",
    "    pred_high = quantile_models[0.9].predict(X_cb_test)\n",
    "    \n",
    "    # Check coverage\n",
    "    in_range = (y_cb_test >= pred_low) & (y_cb_test <= pred_high)\n",
    "    coverage = in_range.mean() * 100\n",
    "    \n",
    "    print(f\"\\n=== Quantile Prediction Results ===\")\n",
    "    print(f\"Expected coverage (10%-90% interval): 80%\")\n",
    "    print(f\"Actual coverage: {coverage:.1f}%\")\n",
    "    print(f\"Average interval width: {(pred_high - pred_low).mean():,.0f}€\")\n",
    "else:\n",
    "    print(\"CatBoost not available - skipping quantile regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-31",
   "metadata": {},
   "outputs": [],
   "source": "if CATBOOST_AVAILABLE:\n    # Visualize quantile predictions\n    fig, ax = plt.subplots(figsize=(10, 6))\n    \n    # Sample for visualization\n    sample_idx = np.random.choice(len(y_cb_test), min(100, len(y_cb_test)), replace=False)\n    sample_idx = np.sort(sample_idx)\n    \n    x_pos = np.arange(len(sample_idx))\n    \n    # Plot intervals (pred_low, pred_mid, pred_high are numpy arrays)\n    ax.fill_between(x_pos, pred_low[sample_idx], pred_high[sample_idx], \n                    alpha=0.3, label='80% Prediction Interval')\n    ax.scatter(x_pos, y_cb_test.iloc[sample_idx].values, c='red', s=20, label='Actual', zorder=5)\n    ax.plot(x_pos, pred_mid[sample_idx], 'b-', lw=1, label='Median Prediction', alpha=0.7)\n    \n    ax.set_xlabel('Sample Index')\n    ax.set_ylabel('Price (€)')\n    ax.set_title('Price Predictions with Uncertainty Intervals')\n    ax.legend()\n    \n    plt.tight_layout()\n    plt.show()"
  },
  {
   "cell_type": "markdown",
   "id": "cell-32",
   "metadata": {},
   "source": [
    "## 9. Save Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model with metadata\n",
    "metadata = {\n",
    "    'model_type': best_model_name,\n",
    "    'feature_cols': model_feature_cols,\n",
    "    'numeric_cols': numeric_cols,\n",
    "    'categorical_cols': categorical_cols,\n",
    "    'target_col': TARGET_COL,\n",
    "    'test_metrics': final_metrics,\n",
    "    'cv_metrics': all_results.get(best_model_name, {}),\n",
    "}\n",
    "\n",
    "save_model(final_model, '../models/price_model.pkl', metadata)\n",
    "\n",
    "print(f\"\\nModel saved with metadata:\")\n",
    "for key, value in metadata.items():\n",
    "    if key in ['feature_cols', 'numeric_cols', 'categorical_cols']:\n",
    "        print(f\"  {key}: {len(value)} columns\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-34",
   "metadata": {},
   "source": "## Summary\n\n### Results\n\nWe trained and compared multiple models for predicting computer prices:\n\n1. **Baseline** - Simple mean prediction\n2. **Ridge Regression** - Linear model with L2 regularization\n3. **Random Forest** - Ensemble of decision trees\n4. **HistGradientBoosting** - sklearn's fast gradient boosting\n5. **CatBoost** - Native categorical handling (if available)\n\n### Data Preparation (from notebook 02)\n\n- Features with >60% missing values removed before modeling\n- CPU/GPU benchmarks matched using close neighbor + family mean imputation\n- Complete benchmark features included:\n  - CPU: `_cpu_mark`, `_cpu_rank`, `_cpu_value`, `_cpu_price_usd`\n  - GPU: `_gpu_mark`, `_gpu_rank`, `_gpu_value`, `_gpu_price_usd`\n- Excluded columns: `cpu_match_score`, `gpu_match_score`, `Ofertas`\n\n### Key Findings\n\n- Best model saved to `models/price_model.pkl`\n- Quantile regression enables price range predictions\n- Error varies by price range (larger absolute errors for expensive items)\n\n### Next Steps\n\n1. Hyperparameter tuning (notebook 04)\n2. Feature selection to reduce complexity\n3. Deploy model via backend API"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}